name: Parquet Data Processor

on:
  workflow_dispatch:
    inputs:
      start_index:
        description: 'Starting index for batch processing'
        required: false
        default: '0'
      total_processed:
        description: 'Total records processed so far'
        required: false
        default: '0'
      batch_size:
        description: 'Number of records to process in each sub-batch'
        required: false
        default: '100'
        type: string
      max_records:
        description: 'Maximum records to process in this workflow run'
        required: false
        default: '500'
        type: string
      total_target:
        description: 'Total records to process (0 for all records)'
        required: false
        default: '0'
        type: string
        
permissions:
  contents: write
  id-token: write
  actions: write

jobs:
  process-urls:
    runs-on: ubuntu-latest
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          
      - name: Install Chrome and ChromeDriver
        run: |
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          
          # Install ChromeDriver
          CHROME_VERSION=$(google-chrome --version | cut -d " " -f 3)
          CHROME_MAJOR_VERSION=$(echo "$CHROME_VERSION" | cut -d "." -f 1)
          wget -q "https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/$CHROME_VERSION/linux64/chromedriver-linux64.zip"
          unzip chromedriver-linux64.zip
          sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
          sudo chmod +x /usr/local/bin/chromedriver
          rm -rf chromedriver-linux64.zip chromedriver-linux64
          
          # Verify installations
          google-chrome --version
          chromedriver --version
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas pyarrow tqdm selenium
          
      - name: Generate Timestamp
        id: timestamp
        run: |
          TS=$(date +'%Y-%m-%d_%H-%M-%S')
          echo "timestamp=$TS" >> $GITHUB_OUTPUT
          
      - name: Process URLs
        id: process_urls
        run: |
          # Create step output file
          echo "GITHUB_OUTPUT=${GITHUB_OUTPUT}"
          
          python .github/scripts/parquet_processor.py \
            --output-dir data/parquet/${{ steps.timestamp.outputs.timestamp }} \
            --batch-size ${{ inputs.batch_size }} \
            --max-records ${{ inputs.max_records }} \
            --start-index ${{ inputs.start_index }} \
            --total-processed ${{ inputs.total_processed }} \
            --total-target ${{ inputs.total_target }} \
            --log-file data/parquet/${{ steps.timestamp.outputs.timestamp }}/processor.log \
            --output-file "${GITHUB_OUTPUT}"
            
      - name: Upload Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: parquet-data-${{ steps.timestamp.outputs.timestamp }}
          path: data/parquet/${{ steps.timestamp.outputs.timestamp }}
          
      - name: Commit and Push Changes
        run: |
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          
          # Function to attempt commit and push
          push_changes() {
            git add data/parquet/${{ steps.timestamp.outputs.timestamp }}
            git commit -m "Parquet data processing [${{ steps.timestamp.outputs.timestamp }}] - Batch starting at ${{ inputs.start_index }}"
            git push && return 0
            return 1
          }
          
          # Try to push directly first
          if push_changes; then
            echo "Changes pushed successfully"
            exit 0
          fi
          
          # If direct push failed, try pull and rebase
          MAX_ATTEMPTS=3
          ATTEMPT=1
          
          while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
            echo "Attempt $ATTEMPT of $MAX_ATTEMPTS to push changes"
            
            # Fetch and rebase
            git fetch origin main
            git rebase origin/main
            
            if push_changes; then
              echo "Changes pushed successfully on attempt $ATTEMPT"
              exit 0
            fi
            
            ATTEMPT=$((ATTEMPT + 1))
            if [ $ATTEMPT -le $MAX_ATTEMPTS ]; then
              echo "Push failed, waiting 10 seconds before retry..."
              sleep 10
            fi
          done
          
          echo "Failed to push changes after $MAX_ATTEMPTS attempts"
          exit 1
          
      - name: Trigger Next Batch or Create Release
        if: success()
        uses: actions/github-script@v7
        env:
          TIMESTAMP: ${{ steps.timestamp.outputs.timestamp }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const nextIndex = parseInt('${{ steps.process_urls.outputs.next_index }}');
            const totalProcessed = parseInt('${{ steps.process_urls.outputs.total_processed }}');
            const hasMore = '${{ steps.process_urls.outputs.has_more }}' === 'true';
            
            if (hasMore) {
              console.log(`Triggering next batch starting at ${nextIndex}`);
              try {
                await github.rest.actions.createWorkflowDispatch({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'parquet_processor.yml',
                  ref: 'main',
                  inputs: {
                    start_index: nextIndex.toString(),
                    total_processed: totalProcessed.toString(),
                    batch_size: '${{ inputs.batch_size }}',
                    max_records: '${{ inputs.max_records }}',
                    total_target: '${{ inputs.total_target }}'
                  }
                });
                console.log('Successfully triggered next batch');
                console.log(`Progress: ${totalProcessed} of ${{ inputs.total_target }} records processed`);
              } catch (error) {
                console.error('Error triggering next batch:', error);
                core.setFailed(error.message);
              }
            } else {
              // Create release for completion
              await github.rest.repos.createRelease({
                owner: context.repo.owner,
                repo: context.repo.repo,
                tag_name: `parquet-complete-${process.env.TIMESTAMP}`,
                name: 'Parquet Processing Complete',
                body: `Completed processing ${totalProcessed} records\n\nFinal batch timestamp: ${process.env.TIMESTAMP}`,
                draft: false,
                prerelease: false
              });
            } 